{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import string\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't read the XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#return list of words\n",
    "def preprocess(sent):\n",
    "    stop_words = list(get_stop_words('en'))         #About 900 stopwords\n",
    "    stemmer = PorterStemmer()\n",
    "    #tokenization\n",
    "    words = str(sent).split()\n",
    "    new_words = []\n",
    "    for w in words:\n",
    "        #lowercase\n",
    "        w = w.lower()\n",
    "        #remove punctuaction, fast\n",
    "        table = str.maketrans({key: None for key in string.punctuation})\n",
    "        w = w.translate(table)\n",
    "        #remove stopwords, you can change the stopwords list in here\n",
    "        if w not in stop_words:\n",
    "            w = stemmer.stem(w)\n",
    "            new_words.append(w)\n",
    "        \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term_freq and its document freq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': Counter({'drink': 1, 'like': 2, 'text': 1, 'wink': 1}),\n",
       " '2': Counter({'drink': 3, 'like': 1, 'text': 1}),\n",
       " '3': Counter({'drink': 1, 'ink': 1, 'like': 1, 'text': 1, 'thing': 1}),\n",
       " '4': Counter({'drink': 1, 'ink': 1, 'like': 1, 'pink': 1, 'text': 1}),\n",
       " '5': Counter({'drink': 1,\n",
       "          'ink': 1,\n",
       "          'like': 1,\n",
       "          'pink': 1,\n",
       "          'text': 1,\n",
       "          'wink': 1})}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return doc{word:freq}\n",
    "def term_freq_line_nick(line):\n",
    "    newline = preprocess(line)  \n",
    "    term_freq = {}\n",
    "    for w in newline:\n",
    "        if w not in term_freq:\n",
    "            term_freq[w] = 0\n",
    "        else:\n",
    "            term_freq[w] = term_freq[w] + 1\n",
    "    return term_freq\n",
    "\n",
    "def term_freq_line(line):\n",
    "    newline = preprocess(line)  \n",
    "    term_freq = defaultdict(int)\n",
    "    for w in newline:\n",
    "        term_freq[w] += 1\n",
    "    return term_freq\n",
    "\n",
    "def count_freq(line):\n",
    "    wordcount = Counter(preprocess(line))\n",
    "    return wordcount\n",
    "    \n",
    "#term_freq and its document freq    \n",
    "def term_freq(file):\n",
    "    term_freq_list = {}\n",
    "    with open(file) as f:\n",
    "\n",
    "        id_num = None\n",
    "        for line in f:\n",
    "            line = line.strip() # remove beginning and trailing whitespaces\n",
    "            if \"ID: \" in line:\n",
    "                line = line.replace(\"ID: \", \"\")\n",
    "                id_num = str(line)\n",
    "            else:\n",
    "                term_freq_list[id_num] = count_freq(line)\n",
    "                #term_freq_list.append((id_num, term_freq_line(line)))\n",
    "        return term_freq_list\n",
    "\n",
    "term_freq('././collections/sample.txt')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get list of documents where this term occured "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get position list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_postion(line):\n",
    "    pos_list = {}\n",
    "    newline = preprocess(line)\n",
    "    for position, w in enumerate(newline):   \n",
    "        #print(w, position)\n",
    "        if w not in pos_list:\n",
    "            # pos_list[w] = []\n",
    "            # pos_list[w].append(position)\n",
    "            pos_list[w] = [position]\n",
    "            \n",
    "        else:\n",
    "            pos_list[w].append(position)\n",
    "    return pos_list\n",
    "\n",
    "        \n",
    "def postion_list(file):\n",
    "    with open(file) as f:\n",
    "        postion_l ={}\n",
    "        id_num = None\n",
    "        for line in f:\n",
    "            line = line.strip() # remove beginning and trailing whitespaces\n",
    "            if \"ID: \" in line:\n",
    "                line = line.replace(\"ID: \", \"\")\n",
    "                id_num = str(line)\n",
    "            else:\n",
    "                #term_freq_list[id_num] = count_freq(line)\n",
    "                postion_l[id_num]= get_postion(line)\n",
    "        return postion_l\n",
    "\n",
    "p_l = postion_list('././collections/sample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': {'1': [0], '2': [0], '3': [0], '4': [0], '5': [0]}, 'like': {'1': [1, 3], '2': [1], '3': [2], '4': [2], '5': [1]}, 'wink': {'1': [2], '5': [2]}, 'drink': {'1': [4], '2': [2, 3, 4], '3': [3], '4': [3], '5': [3]}, 'thing': {'3': [1]}, 'ink': {'3': [4], '4': [1], '5': [5]}, 'pink': {'4': [4], '5': [4]}}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def get_inverted_list(line, document_number, pos_ii):\n",
    "    line = preprocess(line)\n",
    "\n",
    "    for position, word in enumerate(line):\n",
    "        if word in pos_ii:\n",
    "            if document_number in pos_ii[word]:\n",
    "                pos_ii[word][document_number].append(position)\n",
    "            else:\n",
    "                pos_ii[word][document_number] = [position]\n",
    "        else:\n",
    "            pos_ii[word] = {document_number:[position]}\n",
    "    return pos_ii\n",
    "\n",
    "def produce_ii(file):\n",
    "    pos_ii = {}\n",
    "    with open(file) as f:\n",
    "        postion_l ={}\n",
    "        id_num = None\n",
    "        for line in f:\n",
    "            line = line.strip() # remove beginning and trailing whitespaces\n",
    "            if \"ID: \" in line:\n",
    "                line = line.replace(\"ID: \", \"\")\n",
    "                id_num = str(line)\n",
    "            else:\n",
    "                #term_freq_list[id_num] = count_freq(line)\n",
    "                pos_ii = get_inverted_list(line, id_num, pos_ii)\n",
    "        return pos_ii\n",
    "\n",
    "pos_ii = produce_ii('././collections/sample.txt')\n",
    "print(pos_ii)\n",
    "print(len(pos_ii['text'].keys()))\n",
    " \n",
    "words = 'pink'\n",
    "words2 = 'ink'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [0], '2': [0], '3': [0], '4': [0], '5': [0]}"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ii.get('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'drink': [4], 'like': [1, 3]},\n",
       " '2': {'drink': [2, 3, 4], 'like': [1]},\n",
       " '3': {'drink': [3], 'like': [2]},\n",
       " '4': {'drink': [3], 'like': [2]},\n",
       " '5': {'drink': [3], 'like': [1]}}"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_or(words):   \n",
    "    dic2 = {}\n",
    "    doc_l = []\n",
    "    for i in words:\n",
    "        result = pos_ii.get(i)\n",
    "        if result is None:\n",
    "            raise Exception('Word ' + words[i] + ' is not found in the corpora. This behaviour is not implemented yet')\n",
    "        dic2[i] = result\n",
    "    #print(dic2)\n",
    "    #easy version, return documents only\n",
    "#     print(result)\n",
    "#     for doc, pos in result.items():\n",
    "#         if doc not in doc_l:\n",
    "#             doc_l.append(doc)\n",
    "#     print(doc_l)\n",
    "    results_dictionary = {}\n",
    "    for word, pos_l in dic2.items(): \n",
    "        #print(word, pos_l)\n",
    "        for doc, pos in pos_l.items():\n",
    "            if doc not in results_dictionary:\n",
    "                results_dictionary[doc] = {word: pos}\n",
    "                #results_dictionary[doc] = {}\n",
    "                #results_dictionary[doc][word] = pos\n",
    "            else:\n",
    "                results_dictionary[doc][word] = pos\n",
    "    #print(results_dictionary)\n",
    "       \n",
    "    return results_dictionary\n",
    "search_or(['like','drink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': {'drink': [3], 'ink': [4], 'text': [0]},\n",
       " '4': {'drink': [3], 'ink': [1], 'text': [0]},\n",
       " '5': {'drink': [3], 'ink': [5], 'text': [0]}}"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_and(words):\n",
    "    #return all doc contain the words\n",
    "    result = {}\n",
    "    result_or = search_or(words)\n",
    "    for doc, word_pos in result_or.items():\n",
    "        if len(word_pos) == len(words):\n",
    "            if doc not in result:\n",
    "                result[doc] = word_pos\n",
    "    return result\n",
    "\n",
    "search_and(['text', 'ink', 'drink'])\n",
    "                \n",
    "#     count = {}\n",
    "#     for word, doc_pos in result_l.items():\n",
    "#         for doc,v in doc_pos.items():\n",
    "#             if doc not in count:\n",
    "#                 count[doc] = 1\n",
    "#             else:\n",
    "#                 count[doc] = count[doc] + 1\n",
    "#     #print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5']"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['text','drink']\n",
    "not_word = ['ink']\n",
    "def search_not(words):\n",
    "    result_or = search_or(words)\n",
    "    doc_l = []\n",
    "    result = []\n",
    "    for doc, pos_l in result_or.items():\n",
    "        doc_l.append(doc)\n",
    "#return all text in result doc\n",
    "\n",
    "\n",
    "#     for i in range(1,6):\n",
    "#         if i not in doc_l:\n",
    "#             result.append(i)\n",
    "        \n",
    "#     #get all doc contain key words\n",
    "#     exist = search_or(words)\n",
    "#     #get doc list that contain key words\n",
    "#     doc_l = []\n",
    "#     for dic in exist:\n",
    "#         for doc, pos in dic.items():\n",
    "#             doc_l.append(doc)\n",
    "#     #return doc that is not in doc list\n",
    "#     search_not_l=[]\n",
    "#     for dic,v in pos_ii.items():\n",
    "#          for doc,pos in v.items():\n",
    "#                 if doc not in doc_l:\n",
    "#                     search_not_l.append(doc)\n",
    "    return doc_l\n",
    "    \n",
    "search_not(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phrase search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': [0], '2': [0], '3': [0], '4': [0], '5': [0]}\n",
      "{'3': [4], '4': [1], '5': [5]}\n"
     ]
    }
   ],
   "source": [
    "# return all doc contain keywords\n",
    "#search_or(['text','ink','drink'])\n",
    "print(pos_ii.get('text'))\n",
    "print(pos_ii.get('ink'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4']"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def phrase_search(words):\n",
    "    result_and = search_and(words)\n",
    "    result = []\n",
    "    for doc, word_pos in result_and.items():\n",
    "        arr1 = result_and[doc][words[0]]\n",
    "        found = False\n",
    "        for num in arr1:   #check for proximity\n",
    "            for i in range(1,len(words)):\n",
    "                if num + i in result_and[doc][words[i]]:\n",
    "                    found = True\n",
    "                else:\n",
    "                    found = False\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if found:\n",
    "           result.append(doc)\n",
    "    return result\n",
    "\n",
    "phrase_search(['like','drink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 0.21584882741075853),\n",
       " ('1', 0.14612803567823801),\n",
       " ('3', 0.14612803567823801),\n",
       " ('4', 0.14612803567823801),\n",
       " ('5', 0.14612803567823801)]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lab 3\n",
    "def tf_idf(w):\n",
    "    def Tf(w):\n",
    "        result = []\n",
    "        for doc, word_pos in pos_ii[w].items():\n",
    "            result.append((doc, len(word_pos)))\n",
    "            result2 = sorted(result, key=lambda x: x[1], reverse=True)\n",
    "        return result2\n",
    "\n",
    "    def df():\n",
    "        result = {}\n",
    "        for word, doc_pos in pos_ii.items():\n",
    "            doc_count = 0\n",
    "            for doc, pos in doc_pos.items():\n",
    "                doc_count = doc_count + 1\n",
    "                result[word] = doc_count\n",
    "        return result\n",
    "\n",
    "    def get_N():\n",
    "        count = 0\n",
    "        for word, doc_pos in pos_ii.items():\n",
    "            count += 1 \n",
    "        return count\n",
    "    \n",
    "    def idf():\n",
    "        result = []\n",
    "        for word, doc_num in df().items():\n",
    "        #print (word,doc_num)\n",
    "            idf = np.log10(get_N()/doc_num)\n",
    "            result.append((word,idf))\n",
    "        return result\n",
    "   \n",
    "#tf_idf\n",
    "    def final(w):\n",
    "        term_freq = Tf(w)\n",
    "        for w1 in idf(): \n",
    "            if w1[0] == w:\n",
    "                w_idf = w1[1]  \n",
    "        result_l =[]\n",
    "        for freq in term_freq:\n",
    "            tfidf_result = (np.log10(freq[1])+1) * w_idf \n",
    "            result_l.append((freq[0],tfidf_result))\n",
    "        return result_l\n",
    "    \n",
    "    r = final(w)\n",
    "    \n",
    "    return r\n",
    " \n",
    "tf_idf('drink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
